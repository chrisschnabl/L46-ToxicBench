\section{Conclusion}

This paper looks at the limitations of existing toxicity detection models and evaluates approaches to improve their generalizability across datasets. By analyzing performance across diverse benchmarks, including ToxicChat, RealToxicityPrompts, Jigsaw, and CivilComments, we highlight the weaknesses of existing domain-specific fine-tuned classifier and propose a mixed-dataset fine-tuning classifier to address these gaps.\newline
Our findings show that single-dataset fine-tuning often results in high accuracy and AUROC within the training domain but fails to generalize, with metrics such as precision and recall dropping dramatically on unseen datasets (e.g., a 0.07 precision for ToxicChat models on CivilComments). In contrast, mixed-dataset fine-tuning achieves more balanced performance, with accuracy between 0.93 and 0.97 and AUROC consistently above 0.93, though challenges persist in handling nuanced toxicity, especially in datasets like CivilComments with implicit toxic content.\newline
These results show that mixed-dataset fine-tuning can help to build more robust toxicity classifiers and highlights ongoing challenges in subtle toxicity detection. However, our evaluation is limited in the depth of models tested because of computational constraints. Additionally, addressing all existing gaps might be beyound just mixed-dataset fine-tuning and might require improved annotation practices, metrics tailored to nuanced toxicity, and exploration of more adversarially designed datasets. Future research should focus on developing scalable solutions to these challenges to allow for reliable toxicity detection across diverse contexts.