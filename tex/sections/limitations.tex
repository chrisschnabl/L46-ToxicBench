\section{Limitations}

While this work provides valuable insights into toxicity detection using open-source models, there are several limitations that should be acknowledged. First, we restrict our evaluations to reasonably small models due to computational and cost constraints. Evaluations for these models require approximately 10 hours on a single NVIDIA L4 GPU, incurring an estimated cost of 10 USD. Larger models (e.g. Meta's LLama suite) and more extensive experiments are excluded, as they would require significantly greater computational resources and financial investment, which we estimate to be around 500 to 1000 USD. Additionally, commercial models (Grok, Claude, ChatGPT) accessed via APIs, are not evaluated due to the high cost associated with making tens of thousands of API calls, which limits the scope of our findings to open-source and smaller-scale models.\newline
A more extensive ablation study, including additional datasets and classifiers, is also infeasible given current resources. Fine-tuning every possible dataset-classifier pair would incur time and cost, rendering such experiments impractical. Furthermore, while this work uses standard hyperparameters for fine-tuning, we do not explore hyperparameter optimization or fine-tuning over more epochs, which might yield slight performance improvements but would further increase computational requirements.\newline
Another limitation is that we do not use any optimized prompt selection -- we use representative prompts, but the omission of approaches such as uniformly distributed embeddings or curated prompts from benchmarks like HateCheck~\cite{Hatecheck} may result in less comprehensive evaluations. These techniques could improve model performance, but remain unexplored in this work.\newline
Finally, we also do not examine alternative architectures, such as smaller RNN-based classifiers, or explicitly investigate cost/inference-time versus accuracy trade-offs. Future work could explore these directions to improve the practical applicability of toxicity detection models.