\section{Future Work}
Future work should focus on expanding both the scope and depth of toxicity detection evaluations. This work uses smaller models due to cost and computational constraints -- incorporating commercial and models could also help to answer the state-of-art in detection models.\newline
Synthetic datasets could close gaps in existing benchmarks, e.g. embedding current datasets and interpolating between them could create datasets. Alternatively, linguistic alterations could be synthetically generated. This may help to capture underrepresented toxicity contexts and improve model robustness. Similarly, adversarial datasets could also expose classifier weaknesses and help building evaluations that stress-test models against subtle or context-specific toxicity.\newline
Hyperparameter tuning has not been done in this work. Exploring optimal configurations is expected to yield negligible insights for different datasets and models, but could still be valuable. A full more extensive ablation study across datasets and classifiers could provide even more insights into the dataset characteristics and model performance.\newline
Annotation practices also require closer examination. High inter-annotator agreement, while often desirable and reported by existing work, may inadvertently reduce a model's ability to generalize to nuanced or ambiguous toxicity types. Investigating the effects of annotator selection and agreement levels on dataset reliability and model generalization may improve the overall annotation quality.\newline
Expanding the evaluation framework to include metrics beyond binary classification is another important direction. Current metrics do not capture the subtleties of graded or implicit toxicity. Developing metrics that better reflect these complexities help with assessment of model robustness.\newline
Finally, balancing computational constraints with comprehensive evaluations is crucial. While additional compute resources would enable larger-scale experiments, implementing efficient techniques such as intelligent prompt selection could achieve meaningful results within cost and resource limits of academia. These improvements would contribute to  scalable, adaptable, and robust toxicity detection systems.