{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lmsys/toxic-chat...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bef7269207489682b4e704a3937ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5082 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2281a30267444b988c6c458d91928067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5083 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing allenai/real-toxicity-prompts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77bbc12283340c695a32cea4f7d8e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/99442 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tasksource/jigsaw_toxicity...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f59d9bc06c49ac811afcae3cb3dd1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/159571 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing google/civil_comments...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617eaafdcf214667b5057c5171a86ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1804874 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'lmsys/toxic-chat': Dataset({\n",
       "     features: ['input_ids', 'attention_mask', 'label'],\n",
       "     num_rows: 1667\n",
       " }),\n",
       " 'allenai/real-toxicity-prompts': Dataset({\n",
       "     features: ['input_ids', 'attention_mask', 'label'],\n",
       "     num_rows: 1667\n",
       " }),\n",
       " 'tasksource/jigsaw_toxicity': Dataset({\n",
       "     features: ['input_ids', 'attention_mask', 'label'],\n",
       "     num_rows: 1667\n",
       " }),\n",
       " 'google/civil_comments': Dataset({\n",
       "     features: ['input_ids', 'attention_mask', 'label'],\n",
       "     num_rows: 1667\n",
       " })}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "from dataset_processing import datasets_config, sample_dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "TOXICITY_THRESHOLD = 0.7\n",
    "toxicchat_train = None \n",
    "toxicchat_test = None \n",
    "datasets = {}\n",
    "required_columns = [\"input_ids\", \"attention_mask\", \"label\"] \n",
    "\n",
    "for config in datasets_config:\n",
    "    print(f\"Processing {config['name']}...\")\n",
    "\n",
    "    if config[\"name\"] == \"lmsys/toxic-chat\":\n",
    "        # Load the specific subset of ToxicChat\n",
    "        raw_dataset = load_dataset(config[\"name\"], config[\"subset\"])\n",
    "\n",
    "        toxicchat_train = raw_dataset[\"train\"].map(config[\"preprocess_function\"], fn_kwargs={\"tokenizer\": tokenizer}, batched=True)\n",
    "        toxicchat_test = raw_dataset[\"test\"].map(config[\"preprocess_function\"], fn_kwargs={\"tokenizer\": tokenizer}, batched=True)\n",
    "        toxicchat_train = toxicchat_train.remove_columns([col for col in toxicchat_train.column_names if col not in required_columns])\n",
    "        toxicchat_test = toxicchat_test.remove_columns([col for col in toxicchat_test.column_names if col not in required_columns])\n",
    "        datasets[config[\"name\"]] = sample_dataset(toxicchat_test, sample_size=1667)\n",
    "\n",
    "    else:\n",
    "        # Load and preprocess the train split of other datasets\n",
    "        raw_dataset = load_dataset(config[\"name\"], split=config[\"split\"])\n",
    "        tokenized_dataset = raw_dataset.map(config[\"preprocess_function\"], fn_kwargs={\"tokenizer\": tokenizer}, batched=True)\n",
    "        tokenized_dataset = tokenized_dataset.remove_columns([col for col in tokenized_dataset.column_names if col not in required_columns])\n",
    "        sampled_dataset = sample_dataset(tokenized_dataset, sample_size=3333)\n",
    "        datasets[config[\"name\"]] = sampled_dataset.train_test_split(test_size=0.5, seed=1337)[\"test\"]\n",
    "\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import DataCollatorWithPadding, AutoModelForSequenceClassification\n",
    "from metrics import evaluate_model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "output_dir = \"ablation\"\n",
    "\n",
    "def evaluate_and_store_metrics(model_name: str, hf_repo: str = \"inxoy\"):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(f\"{hf_repo}/{model_name}\")\n",
    "\n",
    "    metrics = {name: evaluate_model(model, dataset, collator, tokenizer) for name, dataset in datasets.items()}\n",
    "\n",
    "    # Print summary \n",
    "    for k, m in metrics.items():\n",
    "        print(f\"| {k} | {m['accuracy']:.4f} | {m['precision']:.4f} | {m['recall']:.4f} | {m['f1']:.4f} |\")\n",
    "\n",
    "    with open(f\"{output_dir}/{model_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(metrics, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_store_metrics(\"distilbert-mixed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jigsaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_store_metrics(\"distilbert-jsaw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Civil Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_store_metrics(\"distilbert-cc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToxicChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_store_metrics(\"distilbert-tc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RealToxicityPrompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_store_metrics(\"distilbert-rtp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ablation/distilbert_jsaw.pkl\", \"rb\") as f:\n",
    "    metrics_dict = pickle.load(f)\n",
    "    for k, m in metrics_dict.items():\n",
    "        print(f\"| {k} | {m['accuracy']:.4f} | {m['precision']:.4f} | {m['recall']:.4f} | {m['f1']:.4f} |\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_repo = \"inxoy\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "output_dir = \"ablation_mixed\"\n",
    "models = [\"distilbert-jsaw\", \"distilbert-rtp\", \"distilbert-tc\", \"distilbert-mixed\", \"distilbert-cc\"]\n",
    "\n",
    "ds = load_dataset(\"inxoy/toxicbench-mixed\")\n",
    "\n",
    "for model_name in models:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(f\"{hf_repo}/{model_name}\")\n",
    "    metrics = evaluate_model(model, dataset, collator, tokenizer)\n",
    "    print(f\"| {k} | {metrics['accuracy']:.4f} | {metrics['precision']:.4f} | {metrics['recall']:.4f} | {metrics['f1']:.4f} |\")\n",
    "\n",
    "    with open(f\"{output_dir}/{model_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ablation_mixed/distilbert-cc.pkl\", 'rb+') as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(f\"inxoy/distilbert-cc\")\n",
    "metrics = evaluate_model(model, dataset, collator, tokenizer)\n",
    "print(f\"| {k} | {metrics['accuracy']:.4f} | {metrics['precision']:.4f} | {metrics['recall']:.4f} | {metrics['f1']:.4f} |\")\n",
    "\n",
    "with open(f\"ablation_mixed/distilbert-cc.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"ablation_mixed/distilbert-jsaw.pkl\", \"rb+\") as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"ablation_mixed/distilbert-mixed.pkl\", \"rb+\") as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"ablation_mixed/distilbert-rtp.pkl\", \"rb+\") as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"ablation/distilbert_jsaw.pkl\", \"rb+\") as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"ablation/distilbert_tc.pkl\", \"rb+\") as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"ablation/distilbert_mixed.pkl\", \"rb+\") as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"ablation/distilbert-rtp.pkl\", \"rb+\") as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"ablation/distilbert-cc.pkl\", \"rb+\") as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
